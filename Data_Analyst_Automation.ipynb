{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6fee74-0820-4c31-bf1e-e03b5a70b82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL extraction completed â†’ data/raw/sql_output.csv\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def extract_from_sql(db_path, query):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = extract_from_sql(\"test.db\", \"SELECT * FROM sales_table;\")\n",
    "    df.to_csv(\"data/raw/sql_output.csv\", index=False)\n",
    "    print(\"SQL extraction completed â†’ data/raw/sql_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15b56156-1aa1-44bb-8498-cdc11dfb8c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved â†’ data/cleaned/cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "#Data cleaning\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def clean_data(input_path, output_path):\n",
    "    df = pd.read_csv(input_path)\n",
    "\n",
    "    # Standardize column names\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "    # Handle missing values\n",
    "    df = df.fillna({\n",
    "        col: df[col].median() if df[col].dtype != \"object\" else \"Unknown\"\n",
    "        for col in df.columns\n",
    "    })\n",
    "\n",
    "    # Convert date columns\n",
    "    for col in df.columns:\n",
    "        if \"date\" in col:\n",
    "            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Cleaned data saved â†’ {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clean_data(\"data/raw/sample_raw.csv\", \"data/cleaned/cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f568912d-350a-497f-bf2f-ce91b0f18fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insights generated â†’ data/cleaned/insights.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_insights(df):\n",
    "    insights = {}\n",
    "\n",
    "    insights[\"row_count\"] = len(df)\n",
    "    insights[\"column_count\"] = len(df.columns)\n",
    "    insights[\"missing_values\"] = df.isna().sum().to_dict()\n",
    "    insights[\"numeric_summary\"] = df.describe().to_dict()\n",
    "\n",
    "    if \"sales\" in df.columns:\n",
    "        insights[\"total_sales\"] = df[\"sales\"].sum()\n",
    "        insights[\"max_sales\"] = df[\"sales\"].max()\n",
    "        insights[\"min_sales\"] = df[\"sales\"].min()\n",
    "\n",
    "    return insights\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"data/cleaned/cleaned_data.csv\")\n",
    "    insights = generate_insights(df)\n",
    "\n",
    "    pd.DataFrame.from_dict(insights, orient=\"index\").to_csv(\"data/cleaned/insights.csv\")\n",
    "    print(\"Insights generated â†’ data/cleaned/insights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bc0cc00-8ca5-4bf9-89c3-4757074196be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ RUNNING DATA ANALYST PIPELINE\n",
      "\n",
      "ðŸ”¹ Extracting data from SQL...\n",
      "   â†’ Extracted SQL data saved to: data/raw/sql_output.csv\n",
      "ðŸ”¹ Reading raw CSV file...\n",
      "   â†’ Loaded CSV from: data/raw/sample_raw.csv\n",
      "ðŸ”¹ Cleaning data...\n",
      "   â†’ Cleaned data saved to: data/cleaned/cleaned_data.csv\n",
      "ðŸ”¹ Generating insights...\n",
      "   â†’ Insights saved to: data/cleaned/insights.csv\n",
      "\n",
      "ðŸŽ‰ Pipeline completed successfully!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SQL Runner\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 1 â€” EXTRACT DATA\n",
    "# ---------------------------------------------------------\n",
    "def extract_from_sql(db_path, query, output_path):\n",
    "    print(\"ðŸ”¹ Extracting data from SQL...\")\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"   â†’ Extracted SQL data saved to: {output_path}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_from_csv(raw_csv_path):\n",
    "    print(\"ðŸ”¹ Reading raw CSV file...\")\n",
    "    df = pd.read_csv(raw_csv_path)\n",
    "    print(f\"   â†’ Loaded CSV from: {raw_csv_path}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 2 â€” CLEAN DATA\n",
    "# ---------------------------------------------------------\n",
    "def clean_data(df, output_path):\n",
    "    print(\"ðŸ”¹ Cleaning data...\")\n",
    "\n",
    "    # Standardize column names\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "    # Fill missing values\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            df[col] = df[col].fillna(\"Unknown\")\n",
    "        else:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    # Convert date columns\n",
    "    for col in df.columns:\n",
    "        if \"date\" in col:\n",
    "            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"   â†’ Cleaned data saved to: {output_path}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 3 â€” ANALYZE DATA (EDA)\n",
    "# ---------------------------------------------------------\n",
    "def generate_insights(df, output_path):\n",
    "    print(\"ðŸ”¹ Generating insights...\")\n",
    "\n",
    "    insights = {}\n",
    "    insights[\"row_count\"] = len(df)\n",
    "    insights[\"column_count\"] = len(df.columns)\n",
    "    insights[\"missing_values\"] = df.isna().sum().to_dict()\n",
    "    insights[\"numeric_summary\"] = df.describe().to_dict()\n",
    "\n",
    "    if \"sales\" in df.columns:\n",
    "        insights[\"total_sales\"] = df[\"sales\"].sum()\n",
    "        insights[\"max_sales\"] = df[\"sales\"].max()\n",
    "        insights[\"min_sales\"] = df[\"sales\"].min()\n",
    "\n",
    "    # Save insights as CSV\n",
    "    pd.DataFrame.from_dict(\n",
    "        {k: str(v) for k, v in insights.items()},\n",
    "        orient=\"index\",\n",
    "        columns=[\"value\"]\n",
    "    ).to_csv(output_path)\n",
    "\n",
    "    print(f\"   â†’ Insights saved to: {output_path}\")\n",
    "    return insights\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# MASTER RUN FUNCTION\n",
    "# ---------------------------------------------------------\n",
    "def run_pipeline():\n",
    "    print(\"\\nðŸš€ RUNNING DATA ANALYST PIPELINE\\n\")\n",
    "\n",
    "    # Ensure directory structure\n",
    "    os.makedirs(\"data/raw\", exist_ok=True)\n",
    "    os.makedirs(\"data/cleaned\", exist_ok=True)\n",
    "\n",
    "    # Step 1 â€” Extract SQL\n",
    "    extract_from_sql(\n",
    "        db_path=\"test.db\",\n",
    "        query=\"SELECT * FROM sales_table;\",\n",
    "        output_path=\"data/raw/sql_output.csv\"\n",
    "    )\n",
    "\n",
    "    # Step 1b â€” Extract RAW CSV\n",
    "    raw_df = extract_from_csv(\"data/raw/sample_raw.csv\")\n",
    "\n",
    "    # Step 2 â€” Clean\n",
    "    cleaned_df = clean_data(\n",
    "        raw_df,\n",
    "        output_path=\"data/cleaned/cleaned_data.csv\"\n",
    "    )\n",
    "\n",
    "    # Step 3 â€” Insights\n",
    "    generate_insights(\n",
    "        cleaned_df,\n",
    "        output_path=\"data/cleaned/insights.csv\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nðŸŽ‰ Pipeline completed successfully!\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c889a73-19fe-4103-9747-c1ff0aea1db3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
